{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook used code written by Nik Davis. This code will gather data from the Steam Store API using python. Please check out his amazing blog post! https://nik-davis.github.io/posts/2019/steam-data-collection/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard library imports\n",
    "import csv\n",
    "import datetime as dt\n",
    "import json\n",
    "import os\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "# third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from requests.exceptions import SSLError\n",
    "\n",
    "# customisations - ensure tables show all columns\n",
    "pd.set_option(\"display.max_columns\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_request(url, parameters=None):\n",
    "    \"\"\"Return json-formatted response of a get request using optional parameters.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    url : string\n",
    "    parameters : {'parameter': 'value'}\n",
    "        parameters to pass as part of get request\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    json_data\n",
    "        json-formatted response (dict-like)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url=url, params=parameters)\n",
    "    except SSLError as s:\n",
    "        print('SSL Error:', s)\n",
    "        \n",
    "        for i in range(5, 0, -1):\n",
    "            print('\\rWaiting... ({})'.format(i), end='')\n",
    "            time.sleep(1)\n",
    "        print('\\rRetrying.' + ' '*10)\n",
    "        \n",
    "        # recusively try again\n",
    "        return get_request(url, parameters)\n",
    "    \n",
    "    if response:\n",
    "        return response.json()\n",
    "    else:\n",
    "        # response is none usually means too many requests. Wait and try again \n",
    "        print('No response, waiting 10 seconds...')\n",
    "        time.sleep(10)\n",
    "        print('Retrying.')\n",
    "        return get_request(url, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating List of App IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appid</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>Counter-Strike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>Team Fortress Classic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>Day of Defeat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>Deathmatch Classic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>Half-Life: Opposing Force</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   appid                       name\n",
       "0     10             Counter-Strike\n",
       "1     20      Team Fortress Classic\n",
       "2     30              Day of Defeat\n",
       "3     40         Deathmatch Classic\n",
       "4     50  Half-Life: Opposing Force"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://steamspy.com/api.php\"\n",
    "parameters = {\"request\": \"all\"}\n",
    "\n",
    "# request 'all' from steam spy and parse into dataframe\n",
    "json_data = get_request(url, parameters=parameters)\n",
    "steam_spy_all = pd.DataFrame.from_dict(json_data, orient='index')\n",
    "\n",
    "# generate sorted app_list from steamspy data\n",
    "app_list = steam_spy_all[['appid', 'name']].sort_values('appid').reset_index(drop=True)\n",
    "\n",
    "# export disabled to keep consistency across download sessions\n",
    "# app_list.to_csv('../data/download/app_list.csv', index=False)\n",
    "\n",
    "# instead read from stored csv\n",
    "#app_list = pd.read_csv('../data/download/app_list.csv')\n",
    "\n",
    "# display first few rows\n",
    "app_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   appid   1000 non-null   int64 \n",
      " 1   name    1000 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 15.8+ KB\n"
     ]
    }
   ],
   "source": [
    "app_list.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Download Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_app_data(start, stop, parser, pause):\n",
    "    \"\"\"Return list of app data generated from parser.\n",
    "    \n",
    "    parser : function to handle request\n",
    "    \"\"\"\n",
    "    app_data = []\n",
    "    \n",
    "    # iterate through each row of app_list, confined by start and stop\n",
    "    for index, row in app_list[start:stop].iterrows():\n",
    "        print('Current index: {}'.format(index), end='\\r')\n",
    "        \n",
    "        appid = row['appid']\n",
    "        name = row['name']\n",
    "\n",
    "        # retrive app data for a row, handled by supplied parser, and append to list\n",
    "        data = parser(appid, name)\n",
    "        app_data.append(data)\n",
    "\n",
    "        time.sleep(pause) # prevent overloading api with requests\n",
    "    \n",
    "    return app_data\n",
    "\n",
    "\n",
    "def process_batches(parser, app_list, download_path, data_filename, index_filename,\n",
    "                    columns, begin=0, end=-1, batchsize=100, pause=1):\n",
    "    \"\"\"Process app data in batches, writing directly to file.\n",
    "    \n",
    "    parser : custom function to format request\n",
    "    app_list : dataframe of appid and name\n",
    "    download_path : path to store data\n",
    "    data_filename : filename to save app data\n",
    "    index_filename : filename to store highest index written\n",
    "    columns : column names for file\n",
    "    \n",
    "    Keyword arguments:\n",
    "    \n",
    "    begin : starting index (get from index_filename, default 0)\n",
    "    end : index to finish (defaults to end of app_list)\n",
    "    batchsize : number of apps to write in each batch (default 100)\n",
    "    pause : time to wait after each api request (defualt 1)\n",
    "    \n",
    "    returns: none\n",
    "    \"\"\"\n",
    "    print('Starting at index {}:\\n'.format(begin))\n",
    "    \n",
    "    # by default, process all apps in app_list\n",
    "    if end == -1:\n",
    "        end = len(app_list) + 1\n",
    "    \n",
    "    # generate array of batch begin and end points\n",
    "    batches = np.arange(begin, end, batchsize)\n",
    "    batches = np.append(batches, end)\n",
    "    \n",
    "    apps_written = 0\n",
    "    batch_times = []\n",
    "    \n",
    "    for i in range(len(batches) - 1):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        start = batches[i]\n",
    "        stop = batches[i+1]\n",
    "        \n",
    "        app_data = get_app_data(start, stop, parser, pause)\n",
    "        \n",
    "        rel_path = os.path.join(download_path, data_filename)\n",
    "        \n",
    "        # writing app data to file\n",
    "        with open(rel_path, 'a', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=columns, extrasaction='ignore')\n",
    "            \n",
    "            for j in range(3,0,-1):\n",
    "                print(\"\\rAbout to write data, don't stop script! ({})\".format(j), end='')\n",
    "                time.sleep(0.5)\n",
    "            \n",
    "            writer.writerows(app_data)\n",
    "            print('\\rExported lines {}-{} to {}.'.format(start, stop-1, data_filename), end=' ')\n",
    "            \n",
    "        apps_written += len(app_data)\n",
    "        \n",
    "        idx_path = os.path.join(download_path, index_filename)\n",
    "        \n",
    "        # writing last index to file\n",
    "        with open(idx_path, 'w') as f:\n",
    "            index = stop\n",
    "            print(index, file=f)\n",
    "            \n",
    "        # logging time taken\n",
    "        end_time = time.time()\n",
    "        time_taken = end_time - start_time\n",
    "        \n",
    "        batch_times.append(time_taken)\n",
    "        mean_time = statistics.mean(batch_times)\n",
    "        \n",
    "        est_remaining = (len(batches) - i - 2) * mean_time\n",
    "        \n",
    "        remaining_td = dt.timedelta(seconds=round(est_remaining))\n",
    "        time_td = dt.timedelta(seconds=round(time_taken))\n",
    "        mean_td = dt.timedelta(seconds=round(mean_time))\n",
    "        \n",
    "        print('Batch {} time: {} (avg: {}, remaining: {})'.format(i, time_td, mean_td, remaining_td))\n",
    "            \n",
    "    print('\\nProcessing batches complete. {} apps written'.format(apps_written))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_index(download_path, index_filename):\n",
    "    \"\"\"Reset index in file to 0.\"\"\"\n",
    "    rel_path = os.path.join(download_path, index_filename)\n",
    "    \n",
    "    with open(rel_path, 'w') as f:\n",
    "        print(0, file=f)\n",
    "        \n",
    "\n",
    "def get_index(download_path, index_filename):\n",
    "    \"\"\"Retrieve index from file, returning 0 if file not found.\"\"\"\n",
    "    try:\n",
    "        rel_path = os.path.join(download_path, index_filename)\n",
    "\n",
    "        with open(rel_path, 'r') as f:\n",
    "            index = int(f.readline())\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        index = 0\n",
    "        \n",
    "    return index\n",
    "\n",
    "\n",
    "def prepare_data_file(download_path, filename, index, columns):\n",
    "    \"\"\"Create file and write headers if index is 0.\"\"\"\n",
    "    if index == 0:\n",
    "        rel_path = os.path.join(download_path, filename)\n",
    "\n",
    "        with open(rel_path, 'w', newline='') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=columns)\n",
    "            writer.writeheader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading Steam Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAppListBatch(url, parameters):\n",
    "    json_data = get_request(url, parameters=parameters)\n",
    "    steam_id = pd.DataFrame.from_dict(json_data[\"response\"][\"apps\"])\n",
    "    try:\n",
    "        more_results = json_data[\"response\"][\"have_more_results\"]\n",
    "        last_appid =  json_data[\"response\"][\"last_appid\"]\n",
    "    except:\n",
    "        more_results = False\n",
    "        last_appid = False\n",
    "    return more_results, steam_id, last_appid\n",
    "\n",
    "def get_update_ids_old(updatedlist, oldlist):\n",
    "    updatedlist['key1'] = 1\n",
    "    oldlist['key2'] = 1\n",
    "    updatedlist = pd.merge(updatedlist, oldlist, right_on=['steam_appid','name'],left_on=['appid','name'], how = 'outer')\n",
    "    updatedlist = updatedlist[~(updatedlist.key2 == updatedlist.key1)]\n",
    "    updatedlist = updatedlist.drop(['key1','key2','steam_appid'], axis=1)\n",
    "    return updatedlist\n",
    "\n",
    "def get_update_ids(idList, oldFullList):\n",
    "    #We are going to forget about names and only care about IDs.\n",
    "    idList = idList[\"appid\"]\n",
    "    oldFullList = oldFullList[\"steam_appid\"]\n",
    "    oldFullList.columns = [\"appid\"]\n",
    "    updatedList = pd.concat([idList, oldFullList])\n",
    "    updatedList = updatedList.drop_duplicates(keep=False)\n",
    "    updatedList = updatedList.reset_index(drop=True)\n",
    "    return updatedList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAppList():\n",
    "    with open('../api/steam_key.txt') as f:\n",
    "        key = f.read()\n",
    "\n",
    "    url = \"https://api.steampowered.com/IStoreService/GetAppList/v1/?\"\n",
    "    parameters = {\"key\": key}\n",
    "    more_results = True\n",
    "    begin = True\n",
    "    # from the request we get the more_results flag and also the last_appid, so we use them for the next requests.\n",
    "    while (more_results):\n",
    "        more_results, steam_ids, last_appid = getAppListBatch(url, parameters)\n",
    "        parameters[\"last_appid\"] = last_appid\n",
    "        if (begin):\n",
    "            steam_allids = steam_ids\n",
    "            begin = False\n",
    "        else:\n",
    "            steam_allids = pd.concat([steam_allids, steam_ids])\n",
    "    return steam_allids\n",
    "# request 'all' from steam spy and parse into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_steam_request(appid, name):\n",
    "    \"\"\"Unique parser to handle data from Steam Store API.\n",
    "    \n",
    "    Returns : json formatted data (dict-like)\n",
    "    \"\"\"\n",
    "    with open('../api/steam_key.txt') as f:\n",
    "        key = f.read()\n",
    "        \n",
    "    url = \"http://store.steampowered.com/api/appdetails/\"\n",
    "    parameters = {\"appids\": appid, \"key\": key}\n",
    "    \n",
    "    json_data = get_request(url, parameters=parameters)\n",
    "    json_app_data = json_data[str(appid)]\n",
    "    \n",
    "    if json_app_data['success']:\n",
    "        data = json_app_data['data']\n",
    "    else:\n",
    "        data = {'steam_appid': appid}\n",
    "        \n",
    "    return data\n",
    "\n",
    "\n",
    "# Set file parameters\n",
    "download_path = '../data/download/'\n",
    "steam_app_data = 'steam_app_data.csv'\n",
    "steam_app_data_delta = 'steam_app_data_delta.csv'\n",
    "steam_index = 'steam_index.txt'\n",
    "\n",
    "steam_columns = [\n",
    "    'type', 'name', 'steam_appid', 'required_age', 'is_free', 'controller_support',\n",
    "    'dlc', 'detailed_description', 'about_the_game', 'short_description', 'fullgame',\n",
    "    'supported_languages', 'header_image', 'website', 'pc_requirements', 'mac_requirements',\n",
    "    'linux_requirements', 'legal_notice', 'drm_notice', 'ext_user_account_notice',\n",
    "    'developers', 'publishers', 'demos', 'price_overview', 'packages', 'package_groups',\n",
    "    'platforms', 'metacritic', 'reviews', 'categories', 'genres', 'screenshots',\n",
    "    'movies', 'recommendations', 'achievements', 'release_date', 'support_info',\n",
    "    'background', 'content_descriptors'\n",
    "]\n",
    "\n",
    "# Overwrites last index for demonstration (would usually store highest index so can continue across sessions)\n",
    "if (os.path.isfile(download_path+steam_app_data_delta) == False):\n",
    "    reset_index(download_path, steam_index)\n",
    "\n",
    "# Retrieve last index downloaded from file\n",
    "index = get_index(download_path, steam_index)\n",
    "\n",
    "# Wipe or create data file and write headers if no previous  data\n",
    "if (os.path.isfile(download_path+steam_app_data) == False):\n",
    "    prepare_data_file(download_path, steam_app_data, index, steam_columns)\n",
    "    \n",
    "# Wipe or create data file delta and write headers if index is 0\n",
    "if (os.path.isfile(download_path+steam_app_data_delta) == False):\n",
    "    prepare_data_file(download_path, steam_app_data_delta, index, steam_columns)\n",
    "    \n",
    "    \n",
    "# Here we get the list of appids from steam\n",
    "full_steam_ids = getAppList()\n",
    "\n",
    "# Here we get the real list of ids not yet in our dataframe. If this is the first time we are downloading the data, we can skip\n",
    "# This step and instead use the full app_list.\n",
    "try:\n",
    "    oldlist = pd.read_csv('../data/download/steam_app_data.csv', usecols = ['name','steam_appid'])\n",
    "    steam_ids = get_update_ids(full_steam_ids, oldlist)\n",
    "except FileNotFoundError:\n",
    "    print(\"Pre-existing file not found. First time downloading full app data from steam. This will take a while.\\n\")\n",
    "    steam_ids = full_steam_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New IDs detected: 97470\n"
     ]
    }
   ],
   "source": [
    "print(\"New IDs detected: \"+str(len(steam_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 97470 new ids.\n",
      "\n",
      "Starting at index 576:\n",
      "\n",
      "Exported lines 576-675 to steam_app_data_delta.csv. Batch 0 time: 0:02:36 (avg: 0:02:36, remaining: 1 day, 17:52:56)\n",
      "Current index: 746\r"
     ]
    },
    {
     "ename": "ReadTimeout",
     "evalue": "HTTPSConnectionPool(host='store.steampowered.com', port=443): Read timed out. (read timeout=None)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\jdejr\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:403\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_conn(conn)\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    405\u001b[0m     \u001b[38;5;66;03m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jdejr\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1053\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msock\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[1;32m-> 1053\u001b[0m     conn\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified:\n",
      "File \u001b[1;32mc:\\Users\\jdejr\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:419\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    417\u001b[0m     context\u001b[38;5;241m.\u001b[39mload_default_certs()\n\u001b[1;32m--> 419\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m ssl_wrap_socket(\n\u001b[0;32m    420\u001b[0m     sock\u001b[38;5;241m=\u001b[39mconn,\n\u001b[0;32m    421\u001b[0m     keyfile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_file,\n\u001b[0;32m    422\u001b[0m     certfile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcert_file,\n\u001b[0;32m    423\u001b[0m     key_password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_password,\n\u001b[0;32m    424\u001b[0m     ca_certs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mca_certs,\n\u001b[0;32m    425\u001b[0m     ca_cert_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mca_cert_dir,\n\u001b[0;32m    426\u001b[0m     ca_cert_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mca_cert_data,\n\u001b[0;32m    427\u001b[0m     server_hostname\u001b[38;5;241m=\u001b[39mserver_hostname,\n\u001b[0;32m    428\u001b[0m     ssl_context\u001b[38;5;241m=\u001b[39mcontext,\n\u001b[0;32m    429\u001b[0m     tls_in_tls\u001b[38;5;241m=\u001b[39mtls_in_tls,\n\u001b[0;32m    430\u001b[0m )\n\u001b[0;32m    432\u001b[0m \u001b[38;5;66;03m# If we're using all defaults and the connection\u001b[39;00m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;66;03m# is TLSv1 or TLSv1.1 we throw a DeprecationWarning\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;66;03m# for the host.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jdejr\\anaconda3\\Lib\\site-packages\\urllib3\\util\\ssl_.py:449\u001b[0m, in \u001b[0;36mssl_wrap_socket\u001b[1;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m send_sni:\n\u001b[1;32m--> 449\u001b[0m     ssl_sock \u001b[38;5;241m=\u001b[39m _ssl_wrap_socket_impl(\n\u001b[0;32m    450\u001b[0m         sock, context, tls_in_tls, server_hostname\u001b[38;5;241m=\u001b[39mserver_hostname\n\u001b[0;32m    451\u001b[0m     )\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\jdejr\\anaconda3\\Lib\\site-packages\\urllib3\\util\\ssl_.py:493\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_impl\u001b[1;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m server_hostname:\n\u001b[1;32m--> 493\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ssl_context\u001b[38;5;241m.\u001b[39mwrap_socket(sock, server_hostname\u001b[38;5;241m=\u001b[39mserver_hostname)\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\jdejr\\anaconda3\\Lib\\ssl.py:517\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    512\u001b[0m                 do_handshake_on_connect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    513\u001b[0m                 suppress_ragged_eofs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    514\u001b[0m                 server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    515\u001b[0m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[1;32m--> 517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msslsocket_class\u001b[38;5;241m.\u001b[39m_create(\n\u001b[0;32m    518\u001b[0m         sock\u001b[38;5;241m=\u001b[39msock,\n\u001b[0;32m    519\u001b[0m         server_side\u001b[38;5;241m=\u001b[39mserver_side,\n\u001b[0;32m    520\u001b[0m         do_handshake_on_connect\u001b[38;5;241m=\u001b[39mdo_handshake_on_connect,\n\u001b[0;32m    521\u001b[0m         suppress_ragged_eofs\u001b[38;5;241m=\u001b[39msuppress_ragged_eofs,\n\u001b[0;32m    522\u001b[0m         server_hostname\u001b[38;5;241m=\u001b[39mserver_hostname,\n\u001b[0;32m    523\u001b[0m         context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    524\u001b[0m         session\u001b[38;5;241m=\u001b[39msession\n\u001b[0;32m    525\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\jdejr\\anaconda3\\Lib\\ssl.py:1108\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[0;32m   1107\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1108\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_handshake()\n\u001b[0;32m   1109\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\jdejr\\anaconda3\\Lib\\ssl.py:1379\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   1378\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 1379\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mdo_handshake()\n\u001b[0;32m   1380\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mTimeoutError\u001b[0m: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mReadTimeoutError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\jdejr\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    487\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    488\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    489\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[0;32m    490\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    491\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    492\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    493\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    494\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    495\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[0;32m    496\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    497\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    498\u001b[0m     )\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\jdejr\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:798\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    796\u001b[0m     e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[1;32m--> 798\u001b[0m retries \u001b[38;5;241m=\u001b[39m retries\u001b[38;5;241m.\u001b[39mincrement(\n\u001b[0;32m    799\u001b[0m     method, url, error\u001b[38;5;241m=\u001b[39me, _pool\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, _stacktrace\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    800\u001b[0m )\n\u001b[0;32m    801\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[1;32mc:\\Users\\jdejr\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py:550\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    549\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_method_retryable(method):\n\u001b[1;32m--> 550\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m six\u001b[38;5;241m.\u001b[39mreraise(\u001b[38;5;28mtype\u001b[39m(error), error, _stacktrace)\n\u001b[0;32m    551\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\jdejr\\anaconda3\\Lib\\site-packages\\urllib3\\packages\\six.py:770\u001b[0m, in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    769\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m--> 770\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[0;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\jdejr\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:714\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 714\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    715\u001b[0m     conn,\n\u001b[0;32m    716\u001b[0m     method,\n\u001b[0;32m    717\u001b[0m     url,\n\u001b[0;32m    718\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    719\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    720\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    721\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    722\u001b[0m )\n\u001b[0;32m    724\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jdejr\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:406\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    405\u001b[0m     \u001b[38;5;66;03m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n\u001b[1;32m--> 406\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mconn\u001b[38;5;241m.\u001b[39mtimeout)\n\u001b[0;32m    407\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jdejr\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:357\u001b[0m, in \u001b[0;36mHTTPConnectionPool._raise_timeout\u001b[1;34m(self, err, url, timeout_value)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(err, SocketTimeout):\n\u001b[1;32m--> 357\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeoutError(\n\u001b[0;32m    358\u001b[0m         \u001b[38;5;28mself\u001b[39m, url, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead timed out. (read timeout=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m timeout_value\n\u001b[0;32m    359\u001b[0m     )\n\u001b[0;32m    361\u001b[0m \u001b[38;5;66;03m# See the above comment about EAGAIN in Python 3. In Python 2 we have\u001b[39;00m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;66;03m# to specifically catch it and throw the timeout error\u001b[39;00m\n",
      "\u001b[1;31mReadTimeoutError\u001b[0m: HTTPSConnectionPool(host='store.steampowered.com', port=443): Read timed out. (read timeout=None)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# I separated the long process to be able to debug it better.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Set end and chunksize for demonstration - remove to run through entire app list\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Here by default we passed \"app_list\" that contained all the information and saved it, now we will modify it a bit\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# And add pre-processing and post-processing\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdding \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mlen\u001b[39m(steam_ids))\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m new ids.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m process_batches(\n\u001b[0;32m      7\u001b[0m     parser\u001b[38;5;241m=\u001b[39mparse_steam_request,\n\u001b[0;32m      8\u001b[0m     app_list\u001b[38;5;241m=\u001b[39msteam_ids,\n\u001b[0;32m      9\u001b[0m     download_path\u001b[38;5;241m=\u001b[39mdownload_path,\n\u001b[0;32m     10\u001b[0m     data_filename\u001b[38;5;241m=\u001b[39msteam_app_data_delta,\n\u001b[0;32m     11\u001b[0m     index_filename\u001b[38;5;241m=\u001b[39msteam_index,\n\u001b[0;32m     12\u001b[0m     columns\u001b[38;5;241m=\u001b[39msteam_columns,\n\u001b[0;32m     13\u001b[0m     begin\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m576\u001b[39m,\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m#end=10,\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m#batchsize=5\u001b[39;00m\n\u001b[0;32m     16\u001b[0m )\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     19\u001b[0m     oldlist \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/download/steam_app_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[26], line 63\u001b[0m, in \u001b[0;36mprocess_batches\u001b[1;34m(parser, app_list, download_path, data_filename, index_filename, columns, begin, end, batchsize, pause)\u001b[0m\n\u001b[0;32m     60\u001b[0m start \u001b[38;5;241m=\u001b[39m batches[i]\n\u001b[0;32m     61\u001b[0m stop \u001b[38;5;241m=\u001b[39m batches[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 63\u001b[0m app_data \u001b[38;5;241m=\u001b[39m get_app_data(start, stop, parser, pause)\n\u001b[0;32m     65\u001b[0m rel_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(download_path, data_filename)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# writing app data to file\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[26], line 16\u001b[0m, in \u001b[0;36mget_app_data\u001b[1;34m(start, stop, parser, pause)\u001b[0m\n\u001b[0;32m     13\u001b[0m name \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# retrive app data for a row, handled by supplied parser, and append to list\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m data \u001b[38;5;241m=\u001b[39m parser(appid, name)\n\u001b[0;32m     17\u001b[0m app_data\u001b[38;5;241m.\u001b[39mappend(data)\n\u001b[0;32m     19\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(pause) \u001b[38;5;66;03m# prevent overloading api with requests\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[34], line 12\u001b[0m, in \u001b[0;36mparse_steam_request\u001b[1;34m(appid, name)\u001b[0m\n\u001b[0;32m      9\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://store.steampowered.com/api/appdetails/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     10\u001b[0m parameters \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mappids\u001b[39m\u001b[38;5;124m\"\u001b[39m: appid, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkey\u001b[39m\u001b[38;5;124m\"\u001b[39m: key}\n\u001b[1;32m---> 12\u001b[0m json_data \u001b[38;5;241m=\u001b[39m get_request(url, parameters\u001b[38;5;241m=\u001b[39mparameters)\n\u001b[0;32m     13\u001b[0m json_app_data \u001b[38;5;241m=\u001b[39m json_data[\u001b[38;5;28mstr\u001b[39m(appid)]\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m json_app_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msuccess\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "Cell \u001b[1;32mIn[3], line 16\u001b[0m, in \u001b[0;36mget_request\u001b[1;34m(url, parameters)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return json-formatted response of a get request using optional parameters.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124;03m    json-formatted response (dict-like)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 16\u001b[0m     response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url\u001b[38;5;241m=\u001b[39murl, params\u001b[38;5;241m=\u001b[39mparameters)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m s:\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSSL Error:\u001b[39m\u001b[38;5;124m'\u001b[39m, s)\n",
      "File \u001b[1;32mc:\\Users\\jdejr\\anaconda3\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jdejr\\anaconda3\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jdejr\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\jdejr\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:725\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_redirects:\n\u001b[0;32m    723\u001b[0m     \u001b[38;5;66;03m# Redirect resolving generator.\u001b[39;00m\n\u001b[0;32m    724\u001b[0m     gen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolve_redirects(r, request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 725\u001b[0m     history \u001b[38;5;241m=\u001b[39m [resp \u001b[38;5;28;01mfor\u001b[39;00m resp \u001b[38;5;129;01min\u001b[39;00m gen]\n\u001b[0;32m    726\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    727\u001b[0m     history \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\jdejr\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:725\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_redirects:\n\u001b[0;32m    723\u001b[0m     \u001b[38;5;66;03m# Redirect resolving generator.\u001b[39;00m\n\u001b[0;32m    724\u001b[0m     gen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolve_redirects(r, request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 725\u001b[0m     history \u001b[38;5;241m=\u001b[39m [resp \u001b[38;5;28;01mfor\u001b[39;00m resp \u001b[38;5;129;01min\u001b[39;00m gen]\n\u001b[0;32m    726\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    727\u001b[0m     history \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\jdejr\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:266\u001b[0m, in \u001b[0;36mSessionRedirectMixin.resolve_redirects\u001b[1;34m(self, resp, req, stream, timeout, verify, cert, proxies, yield_requests, **adapter_kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m req\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 266\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(\n\u001b[0;32m    267\u001b[0m         req,\n\u001b[0;32m    268\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    269\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    270\u001b[0m         verify\u001b[38;5;241m=\u001b[39mverify,\n\u001b[0;32m    271\u001b[0m         cert\u001b[38;5;241m=\u001b[39mcert,\n\u001b[0;32m    272\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[0;32m    273\u001b[0m         allow_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    274\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39madapter_kwargs,\n\u001b[0;32m    275\u001b[0m     )\n\u001b[0;32m    277\u001b[0m     extract_cookies_to_jar(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcookies, prepared_request, resp\u001b[38;5;241m.\u001b[39mraw)\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;66;03m# extract redirect url, if any, for the next loop\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jdejr\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\jdejr\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:532\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, ReadTimeoutError):\n\u001b[1;32m--> 532\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeout(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, _InvalidHeader):\n\u001b[0;32m    534\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidHeader(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[1;31mReadTimeout\u001b[0m: HTTPSConnectionPool(host='store.steampowered.com', port=443): Read timed out. (read timeout=None)"
     ]
    }
   ],
   "source": [
    "# I separated the long process to be able to debug it better.\n",
    "# Set end and chunksize for demonstration - remove to run through entire app list\n",
    "# Here by default we passed \"app_list\" that contained all the information and saved it, now we will modify it a bit\n",
    "# And add pre-processing and post-processing\n",
    "print(\"Adding \"+str(len(steam_ids))+\" new ids.\\n\")\n",
    "process_batches(\n",
    "    parser=parse_steam_request,\n",
    "    app_list=steam_ids,\n",
    "    download_path=download_path,\n",
    "    data_filename=steam_app_data_delta,\n",
    "    index_filename=steam_index,\n",
    "    columns=steam_columns,\n",
    "    begin=747,\n",
    "    #end=10,\n",
    "    #batchsize=5\n",
    ")\n",
    "\n",
    "try:\n",
    "    oldlist = pd.read_csv('../data/download/steam_app_data.csv')\n",
    "    # We change the old file to backup, so remove any backup named this way before...\n",
    "    os.rename('../data/download/steam_app_data.csv', '../data/download/steam_app_data_backup.csv')\n",
    "    newlist = pd.read_csv('../data/download/steam_app_data_delta.csv')\n",
    "    oldlist = pd.concat([oldlist, newlist], ignore_index=True)\n",
    "    oldlist.to_csv('../data/download/steam_app_data.csv', index=False)\n",
    "except FileNotFoundError:\n",
    "    os.rename('../data/download/steam_app_data_delta.csv', '../data/download/steam_app_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading SteamSpy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting at index 0:\n",
      "\n",
      "Exported lines 0-9 to steamspy_data.csv. Batch 0 time: 0:00:10 (avg: 0:00:10, remaining: 0:17:26)\n",
      "Exported lines 10-19 to steamspy_data.csv. Batch 1 time: 0:00:10 (avg: 0:00:10, remaining: 0:17:17)\n",
      "Exported lines 20-29 to steamspy_data.csv. Batch 2 time: 0:00:12 (avg: 0:00:11, remaining: 0:17:42)\n",
      "Exported lines 30-39 to steamspy_data.csv. Batch 3 time: 0:00:11 (avg: 0:00:11, remaining: 0:17:40)\n",
      "Exported lines 40-49 to steamspy_data.csv. Batch 4 time: 0:00:11 (avg: 0:00:11, remaining: 0:17:29)\n",
      "Exported lines 50-59 to steamspy_data.csv. Batch 5 time: 0:00:12 (avg: 0:00:11, remaining: 0:17:34)\n",
      "Exported lines 60-69 to steamspy_data.csv. Batch 6 time: 0:00:10 (avg: 0:00:11, remaining: 0:17:07)\n",
      "Exported lines 70-79 to steamspy_data.csv. Batch 7 time: 0:00:10 (avg: 0:00:11, remaining: 0:16:42)\n",
      "Exported lines 80-89 to steamspy_data.csv. Batch 8 time: 0:00:10 (avg: 0:00:11, remaining: 0:16:25)\n",
      "Exported lines 90-99 to steamspy_data.csv. Batch 9 time: 0:00:11 (avg: 0:00:11, remaining: 0:16:20)\n",
      "Exported lines 100-109 to steamspy_data.csv. Batch 10 time: 0:00:12 (avg: 0:00:11, remaining: 0:16:18)\n",
      "Exported lines 110-119 to steamspy_data.csv. Batch 11 time: 0:00:37 (avg: 0:00:13, remaining: 0:19:21)\n",
      "Exported lines 120-129 to steamspy_data.csv. Batch 12 time: 0:00:11 (avg: 0:00:13, remaining: 0:18:55)\n",
      "Exported lines 130-139 to steamspy_data.csv. Batch 13 time: 0:00:11 (avg: 0:00:13, remaining: 0:18:27)\n",
      "Exported lines 140-149 to steamspy_data.csv. Batch 14 time: 0:00:10 (avg: 0:00:13, remaining: 0:18:01)\n",
      "Exported lines 150-159 to steamspy_data.csv. Batch 15 time: 0:00:12 (avg: 0:00:13, remaining: 0:17:47)\n",
      "Exported lines 160-169 to steamspy_data.csv. Batch 16 time: 0:00:12 (avg: 0:00:13, remaining: 0:17:31)\n",
      "Exported lines 170-179 to steamspy_data.csv. Batch 17 time: 0:00:11 (avg: 0:00:12, remaining: 0:17:13)\n",
      "Exported lines 180-189 to steamspy_data.csv. Batch 18 time: 0:00:10 (avg: 0:00:12, remaining: 0:16:50)\n",
      "Exported lines 190-199 to steamspy_data.csv. Batch 19 time: 0:00:12 (avg: 0:00:12, remaining: 0:16:34)\n",
      "Exported lines 200-209 to steamspy_data.csv. Batch 20 time: 0:00:11 (avg: 0:00:12, remaining: 0:16:17)\n",
      "Exported lines 210-219 to steamspy_data.csv. Batch 21 time: 0:00:10 (avg: 0:00:12, remaining: 0:15:59)\n",
      "Exported lines 220-229 to steamspy_data.csv. Batch 22 time: 0:00:10 (avg: 0:00:12, remaining: 0:15:39)\n",
      "Exported lines 230-239 to steamspy_data.csv. Batch 23 time: 0:00:10 (avg: 0:00:12, remaining: 0:15:22)\n",
      "Exported lines 240-249 to steamspy_data.csv. Batch 24 time: 0:00:11 (avg: 0:00:12, remaining: 0:15:08)\n",
      "Exported lines 250-259 to steamspy_data.csv. Batch 25 time: 0:00:10 (avg: 0:00:12, remaining: 0:14:51)\n",
      "Exported lines 260-269 to steamspy_data.csv. Batch 26 time: 0:00:10 (avg: 0:00:12, remaining: 0:14:33)\n",
      "Exported lines 270-279 to steamspy_data.csv. Batch 27 time: 0:00:11 (avg: 0:00:12, remaining: 0:14:19)\n",
      "Exported lines 280-289 to steamspy_data.csv. Batch 28 time: 0:00:10 (avg: 0:00:12, remaining: 0:14:05)\n",
      "Exported lines 290-299 to steamspy_data.csv. Batch 29 time: 0:00:11 (avg: 0:00:12, remaining: 0:13:51)\n",
      "Exported lines 300-309 to steamspy_data.csv. Batch 30 time: 0:00:10 (avg: 0:00:12, remaining: 0:13:36)\n",
      "Exported lines 310-319 to steamspy_data.csv. Batch 31 time: 0:00:10 (avg: 0:00:12, remaining: 0:13:21)\n",
      "Exported lines 320-329 to steamspy_data.csv. Batch 32 time: 0:00:10 (avg: 0:00:12, remaining: 0:13:06)\n",
      "Exported lines 330-339 to steamspy_data.csv. Batch 33 time: 0:00:11 (avg: 0:00:12, remaining: 0:12:53)\n",
      "Exported lines 340-349 to steamspy_data.csv. Batch 34 time: 0:00:10 (avg: 0:00:11, remaining: 0:12:39)\n",
      "Exported lines 350-359 to steamspy_data.csv. Batch 35 time: 0:00:10 (avg: 0:00:11, remaining: 0:12:25)\n",
      "Exported lines 360-369 to steamspy_data.csv. Batch 36 time: 0:00:14 (avg: 0:00:12, remaining: 0:12:18)\n",
      "Exported lines 370-379 to steamspy_data.csv. Batch 37 time: 0:00:11 (avg: 0:00:12, remaining: 0:12:06)\n",
      "Exported lines 380-389 to steamspy_data.csv. Batch 38 time: 0:00:11 (avg: 0:00:12, remaining: 0:11:54)\n",
      "Exported lines 390-399 to steamspy_data.csv. Batch 39 time: 0:00:10 (avg: 0:00:11, remaining: 0:11:40)\n",
      "Exported lines 400-409 to steamspy_data.csv. Batch 40 time: 0:00:10 (avg: 0:00:11, remaining: 0:11:27)\n",
      "Exported lines 410-419 to steamspy_data.csv. Batch 41 time: 0:00:11 (avg: 0:00:11, remaining: 0:11:16)\n",
      "Exported lines 420-429 to steamspy_data.csv. Batch 42 time: 0:00:10 (avg: 0:00:11, remaining: 0:11:03)\n",
      "Exported lines 430-439 to steamspy_data.csv. Batch 43 time: 0:00:10 (avg: 0:00:11, remaining: 0:10:50)\n",
      "Exported lines 440-449 to steamspy_data.csv. Batch 44 time: 0:00:10 (avg: 0:00:11, remaining: 0:10:37)\n",
      "Exported lines 450-459 to steamspy_data.csv. Batch 45 time: 0:00:10 (avg: 0:00:11, remaining: 0:10:24)\n",
      "Exported lines 460-469 to steamspy_data.csv. Batch 46 time: 0:00:10 (avg: 0:00:11, remaining: 0:10:11)\n",
      "Exported lines 470-479 to steamspy_data.csv. Batch 47 time: 0:00:11 (avg: 0:00:11, remaining: 0:09:59)\n",
      "Exported lines 480-489 to steamspy_data.csv. Batch 48 time: 0:00:12 (avg: 0:00:11, remaining: 0:09:48)\n",
      "Exported lines 490-499 to steamspy_data.csv. Batch 49 time: 0:00:11 (avg: 0:00:11, remaining: 0:09:36)\n",
      "Exported lines 500-509 to steamspy_data.csv. Batch 50 time: 0:00:10 (avg: 0:00:11, remaining: 0:09:23)\n",
      "Exported lines 510-519 to steamspy_data.csv. Batch 51 time: 0:00:10 (avg: 0:00:11, remaining: 0:09:11)\n",
      "Exported lines 520-529 to steamspy_data.csv. Batch 52 time: 0:00:11 (avg: 0:00:11, remaining: 0:09:00)\n",
      "Exported lines 530-539 to steamspy_data.csv. Batch 53 time: 0:00:10 (avg: 0:00:11, remaining: 0:08:48)\n",
      "Exported lines 540-549 to steamspy_data.csv. Batch 54 time: 0:00:11 (avg: 0:00:11, remaining: 0:08:36)\n",
      "Exported lines 550-559 to steamspy_data.csv. Batch 55 time: 0:00:10 (avg: 0:00:11, remaining: 0:08:24)\n",
      "Exported lines 560-569 to steamspy_data.csv. Batch 56 time: 0:00:10 (avg: 0:00:11, remaining: 0:08:12)\n",
      "Exported lines 570-579 to steamspy_data.csv. Batch 57 time: 0:00:11 (avg: 0:00:11, remaining: 0:08:01)\n",
      "Exported lines 580-589 to steamspy_data.csv. Batch 58 time: 0:00:10 (avg: 0:00:11, remaining: 0:07:49)\n",
      "Exported lines 590-599 to steamspy_data.csv. Batch 59 time: 0:00:10 (avg: 0:00:11, remaining: 0:07:37)\n",
      "Exported lines 600-609 to steamspy_data.csv. Batch 60 time: 0:00:11 (avg: 0:00:11, remaining: 0:07:25)\n",
      "Exported lines 610-619 to steamspy_data.csv. Batch 61 time: 0:00:11 (avg: 0:00:11, remaining: 0:07:14)\n",
      "Exported lines 620-629 to steamspy_data.csv. Batch 62 time: 0:00:12 (avg: 0:00:11, remaining: 0:07:04)\n",
      "Exported lines 630-639 to steamspy_data.csv. Batch 63 time: 0:00:10 (avg: 0:00:11, remaining: 0:06:52)\n",
      "Exported lines 640-649 to steamspy_data.csv. Batch 64 time: 0:00:11 (avg: 0:00:11, remaining: 0:06:41)\n",
      "Exported lines 650-659 to steamspy_data.csv. Batch 65 time: 0:00:10 (avg: 0:00:11, remaining: 0:06:29)\n",
      "Exported lines 660-669 to steamspy_data.csv. Batch 66 time: 0:00:11 (avg: 0:00:11, remaining: 0:06:18)\n",
      "Exported lines 670-679 to steamspy_data.csv. Batch 67 time: 0:00:10 (avg: 0:00:11, remaining: 0:06:06)\n",
      "Exported lines 680-689 to steamspy_data.csv. Batch 68 time: 0:00:10 (avg: 0:00:11, remaining: 0:05:55)\n",
      "Exported lines 690-699 to steamspy_data.csv. Batch 69 time: 0:00:10 (avg: 0:00:11, remaining: 0:05:43)\n",
      "Exported lines 700-709 to steamspy_data.csv. Batch 70 time: 0:00:11 (avg: 0:00:11, remaining: 0:05:32)\n",
      "Exported lines 710-719 to steamspy_data.csv. Batch 71 time: 0:00:10 (avg: 0:00:11, remaining: 0:05:20)\n",
      "Exported lines 720-729 to steamspy_data.csv. Batch 72 time: 0:00:10 (avg: 0:00:11, remaining: 0:05:09)\n",
      "Exported lines 730-739 to steamspy_data.csv. Batch 73 time: 0:00:11 (avg: 0:00:11, remaining: 0:04:58)\n",
      "Exported lines 740-749 to steamspy_data.csv. Batch 74 time: 0:00:10 (avg: 0:00:11, remaining: 0:04:47)\n",
      "Exported lines 750-759 to steamspy_data.csv. Batch 75 time: 0:00:11 (avg: 0:00:11, remaining: 0:04:36)\n",
      "Exported lines 760-769 to steamspy_data.csv. Batch 76 time: 0:00:10 (avg: 0:00:11, remaining: 0:04:24)\n",
      "Exported lines 770-779 to steamspy_data.csv. Batch 77 time: 0:00:11 (avg: 0:00:11, remaining: 0:04:13)\n",
      "Exported lines 780-789 to steamspy_data.csv. Batch 78 time: 0:00:10 (avg: 0:00:11, remaining: 0:04:02)\n",
      "Exported lines 790-799 to steamspy_data.csv. Batch 79 time: 0:00:10 (avg: 0:00:11, remaining: 0:03:51)\n",
      "Exported lines 800-809 to steamspy_data.csv. Batch 80 time: 0:00:10 (avg: 0:00:11, remaining: 0:03:40)\n",
      "Exported lines 810-819 to steamspy_data.csv. Batch 81 time: 0:00:10 (avg: 0:00:11, remaining: 0:03:28)\n",
      "Exported lines 820-829 to steamspy_data.csv. Batch 82 time: 0:00:10 (avg: 0:00:11, remaining: 0:03:17)\n",
      "Exported lines 830-839 to steamspy_data.csv. Batch 83 time: 0:00:11 (avg: 0:00:11, remaining: 0:03:06)\n",
      "Exported lines 840-849 to steamspy_data.csv. Batch 84 time: 0:00:15 (avg: 0:00:11, remaining: 0:02:56)\n",
      "Exported lines 850-859 to steamspy_data.csv. Batch 85 time: 0:00:12 (avg: 0:00:11, remaining: 0:02:45)\n",
      "Exported lines 860-869 to steamspy_data.csv. Batch 86 time: 0:00:10 (avg: 0:00:11, remaining: 0:02:34)\n",
      "Exported lines 870-879 to steamspy_data.csv. Batch 87 time: 0:00:10 (avg: 0:00:11, remaining: 0:02:23)\n",
      "Exported lines 880-889 to steamspy_data.csv. Batch 88 time: 0:00:11 (avg: 0:00:11, remaining: 0:02:12)\n",
      "Exported lines 890-899 to steamspy_data.csv. Batch 89 time: 0:00:12 (avg: 0:00:11, remaining: 0:02:01)\n",
      "Exported lines 900-909 to steamspy_data.csv. Batch 90 time: 0:00:11 (avg: 0:00:11, remaining: 0:01:50)\n",
      "Exported lines 910-919 to steamspy_data.csv. Batch 91 time: 0:00:10 (avg: 0:00:11, remaining: 0:01:39)\n",
      "Exported lines 920-929 to steamspy_data.csv. Batch 92 time: 0:00:10 (avg: 0:00:11, remaining: 0:01:28)\n",
      "Exported lines 930-939 to steamspy_data.csv. Batch 93 time: 0:00:11 (avg: 0:00:11, remaining: 0:01:17)\n",
      "Exported lines 940-949 to steamspy_data.csv. Batch 94 time: 0:00:10 (avg: 0:00:11, remaining: 0:01:06)\n",
      "Exported lines 950-959 to steamspy_data.csv. Batch 95 time: 0:00:10 (avg: 0:00:11, remaining: 0:00:55)\n",
      "Exported lines 960-969 to steamspy_data.csv. Batch 96 time: 0:00:10 (avg: 0:00:11, remaining: 0:00:44)\n",
      "Exported lines 970-979 to steamspy_data.csv. Batch 97 time: 0:00:11 (avg: 0:00:11, remaining: 0:00:33)\n",
      "Exported lines 980-989 to steamspy_data.csv. Batch 98 time: 0:00:11 (avg: 0:00:11, remaining: 0:00:22)\n",
      "Exported lines 990-999 to steamspy_data.csv. Batch 99 time: 0:00:11 (avg: 0:00:11, remaining: 0:00:11)\n",
      "Exported lines 1000-1000 to steamspy_data.csv. Batch 100 time: 0:00:02 (avg: 0:00:11, remaining: 0:00:00)\n",
      "\n",
      "Processing batches complete. 1000 apps written\n"
     ]
    }
   ],
   "source": [
    "def parse_steamspy_request(appid, name):\n",
    "    \"\"\"Parser to handle SteamSpy API data.\"\"\"\n",
    "    url = \"https://steamspy.com/api.php\"\n",
    "    parameters = {\"request\": \"appdetails\", \"appid\": appid}\n",
    "    \n",
    "    json_data = get_request(url, parameters)\n",
    "    return json_data\n",
    "\n",
    "\n",
    "# set files and columns\n",
    "download_path = '../data/download'\n",
    "steamspy_data = 'steamspy_data.csv'\n",
    "steamspy_index = 'steamspy_index.txt'\n",
    "\n",
    "steamspy_columns = [\n",
    "    'appid', 'name', 'developer', 'publisher', 'score_rank', 'positive',\n",
    "    'negative', 'userscore', 'owners', 'average_forever', 'average_2weeks',\n",
    "    'median_forever', 'median_2weeks', 'price', 'initialprice', 'discount',\n",
    "    'languages', 'genre', 'ccu', 'tags'\n",
    "]\n",
    "\n",
    "reset_index(download_path, steamspy_index)\n",
    "index = get_index(download_path, steamspy_index)\n",
    "\n",
    "# Wipe data file if index is 0\n",
    "prepare_data_file(download_path, steamspy_data, index, steamspy_columns)\n",
    "\n",
    "process_batches(\n",
    "    parser=parse_steamspy_request,\n",
    "    app_list=app_list,\n",
    "    download_path=download_path, \n",
    "    data_filename=steamspy_data,\n",
    "    index_filename=steamspy_index,\n",
    "    columns=steamspy_columns,\n",
    "    begin=index,\n",
    "    batchsize=10,\n",
    "    pause=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
